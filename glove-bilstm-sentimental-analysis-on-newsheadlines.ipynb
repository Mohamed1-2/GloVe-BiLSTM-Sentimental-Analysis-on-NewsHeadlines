{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement🧨\n\nCreate a Bidirectional LSTM classifier to predict sentiment in news headlines by using transfer learning with glove word embeddings (without using embedding layer)","metadata":{"id":"GhaNSLawKoEw"}},{"cell_type":"code","source":"from IPython import display\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n!wget https://wp.technologyreview.com/wp-content/uploads/2018/10/confusednewsrobot-01-11.gif\nimg=('./confusednewsrobot-01-11.gif')\nwith open(img,'rb') as f:\n    display.Image(data=f.read(), format='png')\n","metadata":{"id":"KRu6cQcTKWeE","outputId":"5988be70-dd63-419c-98a4-08bd387552f6","execution":{"iopub.status.busy":"2022-03-05T12:23:10.396697Z","iopub.execute_input":"2022-03-05T12:23:10.397328Z","iopub.status.idle":"2022-03-05T12:23:11.378519Z","shell.execute_reply.started":"2022-03-05T12:23:10.397291Z","shell.execute_reply":"2022-03-05T12:23:11.377834Z"},"_kg_hide-input":true,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Import Libraries**","metadata":{"id":"MpR3bFx77MVT"}},{"cell_type":"code","source":"#for data analysis and modeling\nimport nltk\nnltk.download('stopwords')\n\nfrom tkinter import *\nfrom PIL import ImageTk, Image\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing import text, sequence \nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nfrom matplotlib import pyplot\nimport html #Messing with HTML content, like &amp;\nimport string #String Processing\nimport seaborn as sns\nfrom collections import Counter\n#for text cleaning\nimport string\nimport re #Regular Expressions lib\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words('english'))\nfrom tensorflow.keras.preprocessing.text import Tokenizer #Add tokenizer for tokenization\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences \nfrom tensorflow.keras.layers import LSTM, GRU, Dense, Embedding,LeakyReLU,GlobalMaxPooling1D,GlobalAveragePooling1D, Dropout,Activation,GlobalMaxPool1D,Bidirectional,BatchNormalization,Flatten,MaxPooling1D,TimeDistributed,TimeDistributed,Conv1D,Conv2D,MaxPooling2D,GlobalMaxPooling2D\nfrom IPython.display import display, HTML\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn import metrics\nfrom nltk.util import ngrams\nfrom tqdm import tqdm\nfrom IPython.display import display, HTML\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix, accuracy_score,f1_score,precision_score,recall_score\nimport emoji \n#for visualization\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport operator\nimport random\n\n!pip install emoji\n\nimport emoji\n# Wordcloud\nimport numpy as np\nfrom wordcloud import WordCloud\n# u may need to install \n! pip install kaggle\nfrom collections import Counter\n","metadata":{"id":"sV6O_X_q7N45","outputId":"562433ea-3201-430e-c528-084a02d29230","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T22:42:50.647560Z","iopub.execute_input":"2022-03-05T22:42:50.648134Z","iopub.status.idle":"2022-03-05T22:43:11.532334Z","shell.execute_reply.started":"2022-03-05T22:42:50.648094Z","shell.execute_reply":"2022-03-05T22:43:11.531385Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Load the dataset**","metadata":{"id":"mbYpObBg7xqc"}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/newssentimentanalysis/News/train.csv') \ntest_data = pd.read_csv('../input/newssentimentanalysis/News/test.csv')\nval_data = pd.read_csv('../input/newssentimentanalysis/News/validation.csv')","metadata":{"id":"avBFh0ET7w2i","execution":{"iopub.status.busy":"2022-03-05T22:43:32.425194Z","iopub.execute_input":"2022-03-05T22:43:32.425807Z","iopub.status.idle":"2022-03-05T22:43:32.635812Z","shell.execute_reply.started":"2022-03-05T22:43:32.425752Z","shell.execute_reply":"2022-03-05T22:43:32.635054Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"\n\n> A quick look at the datasets\n\n","metadata":{"id":"Vmk9yzYnBYcT"}},{"cell_type":"code","source":"train_data.head()\n","metadata":{"id":"QlF5sG8aAAk5","outputId":"43e8b64c-5914-4aca-f0f0-2b98fcc1c2d0","execution":{"iopub.status.busy":"2022-03-05T22:43:33.098800Z","iopub.execute_input":"2022-03-05T22:43:33.099033Z","iopub.status.idle":"2022-03-05T22:43:33.119922Z","shell.execute_reply.started":"2022-03-05T22:43:33.099006Z","shell.execute_reply":"2022-03-05T22:43:33.119284Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_data.head()\n","metadata":{"id":"m1S1tgk1Bpdx","outputId":"b9b5238e-0a07-4fcd-e8c9-87b26612aa64","execution":{"iopub.status.busy":"2022-03-05T22:43:33.291724Z","iopub.execute_input":"2022-03-05T22:43:33.291914Z","iopub.status.idle":"2022-03-05T22:43:33.299252Z","shell.execute_reply.started":"2022-03-05T22:43:33.291890Z","shell.execute_reply":"2022-03-05T22:43:33.298613Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"val_data.head()","metadata":{"id":"vIrMyDXPBsow","outputId":"38776d83-d55a-46e5-894b-c981c8df43a3","execution":{"iopub.status.busy":"2022-03-05T22:43:33.699551Z","iopub.execute_input":"2022-03-05T22:43:33.700105Z","iopub.status.idle":"2022-03-05T22:43:33.707772Z","shell.execute_reply.started":"2022-03-05T22:43:33.700065Z","shell.execute_reply":"2022-03-05T22:43:33.706946Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Data shape\ntrain_data.shape, test_data.shape,val_data.shape","metadata":{"id":"gyMx09rTBtHQ","outputId":"6107c568-4578-4ce4-d44f-8fabc1a15139","execution":{"iopub.status.busy":"2022-03-05T22:43:34.020935Z","iopub.execute_input":"2022-03-05T22:43:34.021223Z","iopub.status.idle":"2022-03-05T22:43:34.028645Z","shell.execute_reply.started":"2022-03-05T22:43:34.021195Z","shell.execute_reply":"2022-03-05T22:43:34.028037Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing 🛠**","metadata":{"id":"euyDIoKdnjbp"}},{"cell_type":"code","source":"#Check for Null Values\nprint(\"Training Set:\\n\", train_data.isnull().any()) #Check for null values in the training set\nprint(\"Validation Set:\\n\", val_data.isnull().any()) #Check for null values in the validation set\nprint(\"Testing Set:\\n\", test_data.isnull().any()) #Check for null values in the testing set","metadata":{"id":"wVm6-fAhB6nn","outputId":"011efca4-ed63-48a9-9fc8-bcfefe195e7c","execution":{"iopub.status.busy":"2022-03-05T22:43:34.533950Z","iopub.execute_input":"2022-03-05T22:43:34.534183Z","iopub.status.idle":"2022-03-05T22:43:34.552194Z","shell.execute_reply.started":"2022-03-05T22:43:34.534157Z","shell.execute_reply":"2022-03-05T22:43:34.551199Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Great, we dont have any null values 😊\n\n","metadata":{"id":"VfbDUc_jCCCY"}},{"cell_type":"code","source":"# check the coulmns for each sub data \nprint(train_data.columns)\nprint(val_data.columns)\nprint(test_data.columns)","metadata":{"id":"LTyvf6msCAJH","outputId":"afa31218-386b-441a-9522-3e8e83a9cde9","execution":{"iopub.status.busy":"2022-03-05T22:43:34.990559Z","iopub.execute_input":"2022-03-05T22:43:34.990986Z","iopub.status.idle":"2022-03-05T22:43:34.996988Z","shell.execute_reply.started":"2022-03-05T22:43:34.990955Z","shell.execute_reply":"2022-03-05T22:43:34.996292Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# change the sentiments from -1 to 2 to 0 to 3 for future use  \ntrain_data['0'] += 1\nval_data['1'] += 1\ntest_data['1'] += 1\n\nprint(train_data.head(10))\nprint(val_data.head(10))\nprint(test_data.head(10))","metadata":{"id":"T8AMfkCmDtL5","outputId":"a69450f9-8b18-4de9-b101-35f302efe228","execution":{"iopub.status.busy":"2022-03-05T22:43:35.245820Z","iopub.execute_input":"2022-03-05T22:43:35.246139Z","iopub.status.idle":"2022-03-05T22:43:35.262315Z","shell.execute_reply.started":"2022-03-05T22:43:35.246108Z","shell.execute_reply":"2022-03-05T22:43:35.261430Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# change the coulmns name \ntrain_data.rename(columns = {\"Dr M now interim PM as Agong accepts his resignation\":'news',\"0\":\"sentiments\"}, inplace = True)\nval_data.rename(columns = {\"buzz: malaysia 's hengyuan sells light naphtha to oil major\":'news',\"1\":\"sentiments\"}, inplace = True)\ntest_data.rename(columns = {\"fgv explains accounting treatment of replanting cost\":'news',\"1\":\"sentiments\"}, inplace = True)\n\nprint(train_data.head(10))\nprint(val_data.head(10))\nprint(test_data.head(10))\n\nprint(train_data.shape)\nprint(val_data.shape)\nprint(test_data.shape)","metadata":{"id":"8LkUcBnJE6Yf","outputId":"63a137c8-7fbb-46b9-cd49-60562811263a","execution":{"iopub.status.busy":"2022-03-05T22:43:35.498299Z","iopub.execute_input":"2022-03-05T22:43:35.498658Z","iopub.status.idle":"2022-03-05T22:43:35.513598Z","shell.execute_reply.started":"2022-03-05T22:43:35.498628Z","shell.execute_reply":"2022-03-05T22:43:35.512856Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**we can see that the training data has over 96% of the whole datasets with almost 2% for Val and test datasets. therefore we are going to resplit them as by :**\n* 80% - train set,\n* 10% - validation set,\n* 10% - test set","metadata":{}},{"cell_type":"code","source":"trainData = train_data.copy() #Get the training data\ntestData = test_data.copy() #Get the testing data\nvalidData = val_data.copy() #Get the validation data\n\nfull_data = trainData.append(validData, ignore_index = True) #Combine the training and validation datasets\nfull_data = full_data.append(testData, ignore_index = True) #Combine all datasets\nprint(len(full_data)) #Print the length of the datasets","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:43:36.027282Z","iopub.execute_input":"2022-03-05T22:43:36.027634Z","iopub.status.idle":"2022-03-05T22:43:36.039797Z","shell.execute_reply.started":"2022-03-05T22:43:36.027605Z","shell.execute_reply":"2022-03-05T22:43:36.039028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"full_data","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:43:36.182263Z","iopub.execute_input":"2022-03-05T22:43:36.182502Z","iopub.status.idle":"2022-03-05T22:43:36.197026Z","shell.execute_reply.started":"2022-03-05T22:43:36.182475Z","shell.execute_reply":"2022-03-05T22:43:36.196290Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**before we split the dataset lets check if we have the same sentiments labelled differently and see if we have duplicate news**","metadata":{"id":"xjGGwc2Vrrfm"}},{"cell_type":"code","source":"new_data = full_data.groupby(['news']).nunique().sort_values(by='sentiments', ascending=False)\nnew_data = new_data[new_data['sentiments'] > 1]['sentiments']\nprint(len(new_data))\nnew_data.index.tolist()\n","metadata":{"id":"G6fhRaGxqyTQ","outputId":"49371b0d-6f58-4ad4-f46c-8bd18a6bbe0c","execution":{"iopub.status.busy":"2022-03-05T22:43:36.796469Z","iopub.execute_input":"2022-03-05T22:43:36.796668Z","iopub.status.idle":"2022-03-05T22:43:36.927120Z","shell.execute_reply.started":"2022-03-05T22:43:36.796644Z","shell.execute_reply":"2022-03-05T22:43:36.926437Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":">we need to relabel 104 news headlines","metadata":{}},{"cell_type":"code","source":"full_data.loc[full_data['news'] == 'Top Glove says it has no links to flagged illegal investment scheme Top Gloves Investment','sentiments'] = 1\nfull_data.loc[full_data['news'] == 'scientex to buy melaka land for mixed property development','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'media prima 3q net loss narrows on lower restructuring expenses','sentiments'] = 0\nfull_data.loc[full_data['news'] == 'Genting group joins bid for digital banking licence via PUC','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'daibochi gets myanmar nod to commence jv packaging operations','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'media prima announces senior management changes','sentiments'] = 0\nfull_data.loc[full_data['news'] == 'UEM Sunrise may rebound further, says RHB Retail Research','sentiments'] = 0\nfull_data.loc[full_data['news'] == 'mahb passenger traffic up 7.8% y-o-y in august','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'muar ban lee fails to sell oil palm unit as mou expires','sentiments'] = 0\nfull_data.loc[full_data['news'] == \"former pos malaysia ceo joins airasia 's logistics arm\",'sentiments'] = 1\nfull_data.loc[full_data['news'] == \"dewan rakyat approves repeal of anti-fake news law\",'sentiments'] = 0\nfull_data.loc[full_data['news'] == \"notion consolidating, says alliancedbs research\",'sentiments'] = 1\nfull_data.loc[full_data['news'] == \"moody 's ups mahb 's ratings outlook to stable from negative\",'sentiments'] = 2\nfull_data.loc[full_data['news'] == \"bears in firm control of fbm small cap index, says rhb retail research\",'sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'edra power says no rfp issued to hire banks for ipo','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'Bersatu to announce formalisation of sacking of five party leaders','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'southern steel may climb higher, says rhb retail research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'EVENING 5: Five things you need to know today ','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  \"ghl systems minority shareholders advised to reject actis ' takeover offer\",'sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'sime darby unveils board line-up for plantation, property pure plays','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'r&a files police report against ex-md','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'cimb consolidating, says alliancedbs research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'ekovest 3q net profit largely flat on one-off expense','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'klci edges up in line with regional gains','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'frontken may climb higher, says rhb retail research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'ppb disposes of myanmar packaging business for us$2.4m','sentiments'] = 1\nfull_data.loc[full_data['news'] == 'sc sets up fintech bridges with major financial centres','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'capital market regulators launch asean green bond standards','sentiments'] = 1\nfull_data.loc[full_data['news'] == \"sc revokes bankrupt 's licence\",'sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'damansara realty bags rm5m contract renewals from tm','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'klci reverses gains as sellers outpace buyers','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'ikhmas jaya bags rm62.4m contract','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  '1mdb-linked prince turki among those nabbed for corruption in saudi arabia','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'berjaya media eyes diversification into new businesses','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'eita bags contracts worth rm126m for lrt3 project','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'kim teck cheong consolidated to realise its investments in fy19','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'any policy mishap will put the ringgit at risk, says marc','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'motion to reopen probe into 1mdb passed by dewan rakyat','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'ekuinas sells tenby education group','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'dialog confident of another record year in fy18','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'kelington may climb higher, says rhb retail research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'mms ventures may rise higher, says rhb retail research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==    'gabungan aqrs ceo ups stake in majority shareholder','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'maswings to serve rural air service routes until 2024','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'nor mohamed yakcop quits as khazanah deputy chair','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'kronologi asia may rebound higher, says rhb retail research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   'petra energy bags mcm services job from petronas carigali','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'sapura energy aborts jv with subsea 7','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'berjaya sports toto faces competition from illegal nfos','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'idimension proposes capital reduction, share consolidation','sentiments'] = 1\nfull_data.loc[full_data['news'] ==   'klci edges up in line with firmer regional markets','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'renewed buying interest emerged in ghl systems, says alliancedbs research','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'utusan 1q net loss narrows on lower costs','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'bnm says meps has no cash withdrawal issues','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'pacific mutual warns of more market volatility ahead','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'uem sunrise to provide one-stop real estate management services','sentiments'] = 1\nfull_data.loc[full_data['news'] ==   'klci edges up in early trade, gains seen limited','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'tiong hiew king steps down as mcil chairman','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'bison requests one-day suspension to make material announcement','sentiments'] = 1\nfull_data.loc[full_data['news'] ==    'puncak niaga gapped up, says alliancedbs research ','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'plato capital, oxley to also partner airasia in china venture','sentiments'] = 2\nfull_data.loc[full_data['news'] ==   \"westports confirms interest in colombo port 's new terminal\",'sentiments'] = 1\nfull_data.loc[full_data['news'] ==    'Get Vaccinated! If You Are Not Part Of The Solution, You Are Part Of The Problem.','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  \"dnex gets more time to challenge mycc 's proposed fine\",'sentiments'] = 1\nfull_data.loc[full_data['news'] ==   'petrol prices up by four sen per litre','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'COVID-19','sentiments'] = 0\nfull_data.loc[full_data['news'] ==   'market seen to trade sideways','sentiments'] = 1\nfull_data.loc[full_data['news'] ==   \"kedah rejects drb-hicom 's bid to change langkawi land 's status\",'sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'mrcb bags rm204.7m worth of infrastructure jobs','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'rhb partners imoney for express personal loan applications','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'KLCI settles down 3.04 points at 1,588.42 at 12:30pm','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'klci pares gains as decliners overtake advancers','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'sc sues two individuals for insider trading involving gw plastics shares','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'klci edges higher, tracks regional gains ','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'th plantations ceo quits after a week on garden leave','sentiments'] = 0\nfull_data.loc[full_data['news'] == \"reach energy 's rm180m private placement off the table\",'sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'klci to trend sideways, stay above 1,780-level ','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'scicom to develop tourism management system for cambodia','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'klci edges higher, select blue chips lift','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'klci pares gains as regional markets retreat','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'klci extends gains in line with regional markets','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'epf, kwasa land sign corporate integrity pledge','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'cypark gapped up, says alliancedbs research','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'daikin reintroduces home central air conditioning system','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'petrol prices down by one sen per litre','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'hsbc appoints new co-heads of global banking for malaysia','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'sentul police quarters make way for mrt project','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'wah seong posts profitable 2q on improved o&g contribution','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'chin hin founder buys 15% stake in boon koon','sentiments'] = 1\nfull_data.loc[full_data['news'] ==  'petrol prices down by three sen per litre','sentiments'] = 2\nfull_data.loc[full_data['news'] ==  'ni hsin announces demise of managing director chen shien yee','sentiments'] = 0\nfull_data.loc[full_data['news'] ==  'hock seng lee boardroom tussle ends with setting aside of court order','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'ringgit strengthens against us dollar','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'bimb looking at group-wide restructuring, says ceo','sentiments'] = 0\nfull_data.loc[full_data['news'] == 'foreign outflows from malaysia stocks gain momentum','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'market to remain bullish','sentiments'] = 2\nfull_data.loc[full_data['news'] == 'investkl targets to secure 10 mncs this year','sentiments'] = 1\nfull_data.loc[full_data['news'] == 'klci pares loss as select blue chips advance'] = 0\nfull_data.loc[full_data['news'] ==  'versatile creative md, cfo served show-cause letters'] = 1\nfull_data.loc[full_data['news'] ==   'pentamaster may trend higher, says rhb retail research'] = 2\nfull_data.loc[full_data['news'] ==   'klci ticks up in line with regional markets'] = 2\nfull_data.loc[full_data['news'] ==    'astro radio remains top radio network in malaysia'] = 2\nfull_data.loc[full_data['news'] ==    's p setia hungry for more developments in australia'] = 2\nfull_data.loc[full_data['news'] ==    'klci retreats on mild profit taking'] = 0\n\n ","metadata":{"id":"hkMBk9EIJ-S8","execution":{"iopub.status.busy":"2022-03-05T22:43:37.309783Z","iopub.execute_input":"2022-03-05T22:43:37.310118Z","iopub.status.idle":"2022-03-05T22:43:38.239606Z","shell.execute_reply.started":"2022-03-05T22:43:37.310085Z","shell.execute_reply":"2022-03-05T22:43:38.238854Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"new_data = full_data.groupby(['news']).nunique().sort_values(by='sentiments', ascending=False)\nnew_data = new_data[new_data['sentiments'] > 1]['sentiments']\nnew_data.index.tolist()","metadata":{"id":"ag0fy9RJ_Ey2","outputId":"f859a588-a62e-40fc-8c52-2d7bfd8c1a4f","execution":{"iopub.status.busy":"2022-03-05T22:43:38.241180Z","iopub.execute_input":"2022-03-05T22:43:38.241430Z","iopub.status.idle":"2022-03-05T22:43:38.383267Z","shell.execute_reply.started":"2022-03-05T22:43:38.241394Z","shell.execute_reply":"2022-03-05T22:43:38.382601Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Lets check for unique news headlines for our data (we may have duplicate news)**","metadata":{"id":"zCeZEqEfeOI-"}},{"cell_type":"code","source":"\nprint(\"Unique News in train data :\",len(full_data['news'].unique()))\nprint(\"All News in train data : \",len(full_data['news']))","metadata":{"id":"GiXxt_86HaK1","outputId":"d02923b4-fa55-47dd-d998-9d3a0d45d020","execution":{"iopub.status.busy":"2022-03-05T22:43:38.384630Z","iopub.execute_input":"2022-03-05T22:43:38.384888Z","iopub.status.idle":"2022-03-05T22:43:38.397768Z","shell.execute_reply.started":"2022-03-05T22:43:38.384853Z","shell.execute_reply":"2022-03-05T22:43:38.396781Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**We have about 1566 duplicate news in full dataset,so we have to remove them before building our model**\n","metadata":{"id":"3cYygkYVfX9v"}},{"cell_type":"code","source":"full_data = full_data.drop_duplicates(subset=['news']).reset_index(drop=True)\nprint(len(full_data))\n\n","metadata":{"id":"lcd7fhM86LAz","outputId":"400322b0-d133-4fa3-890f-2cc1843fac77","execution":{"iopub.status.busy":"2022-03-05T22:43:38.399641Z","iopub.execute_input":"2022-03-05T22:43:38.399946Z","iopub.status.idle":"2022-03-05T22:43:38.421072Z","shell.execute_reply.started":"2022-03-05T22:43:38.399911Z","shell.execute_reply":"2022-03-05T22:43:38.420250Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(full_data[:20])\n","metadata":{"id":"H7rgG0TyBZiX","outputId":"55d8da85-c716-450a-e64d-9b3c63d682fb","execution":{"iopub.status.busy":"2022-03-05T22:43:38.584619Z","iopub.execute_input":"2022-03-05T22:43:38.585131Z","iopub.status.idle":"2022-03-05T22:43:38.590857Z","shell.execute_reply.started":"2022-03-05T22:43:38.585100Z","shell.execute_reply":"2022-03-05T22:43:38.590036Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Now Lets split the dataset \ntrain_data, validate_data, test_data = np.split(full_data.sample(frac=1, random_state=42), \n                       [int(.8*len(full_data)), int(.9*len(full_data))])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:43:38.792978Z","iopub.execute_input":"2022-03-05T22:43:38.793272Z","iopub.status.idle":"2022-03-05T22:43:38.807387Z","shell.execute_reply.started":"2022-03-05T22:43:38.793242Z","shell.execute_reply":"2022-03-05T22:43:38.806759Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_data=train_data.reset_index(drop=True)\nvalidate_data=validate_data.reset_index(drop=True)\ntest_data=test_data.reset_index(drop=True)\nprint(train_data)\nprint(validate_data)\nprint(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:43:39.048961Z","iopub.execute_input":"2022-03-05T22:43:39.049683Z","iopub.status.idle":"2022-03-05T22:43:39.065232Z","shell.execute_reply.started":"2022-03-05T22:43:39.049645Z","shell.execute_reply":"2022-03-05T22:43:39.064107Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Lets see the sentements for each dataset\n\n","metadata":{"id":"Shddcl0ZG4mc"}},{"cell_type":"code","source":"sentiment = {2:\"positive\",1:\"neutral\",0:\"negative\"}\ntrain_data[\"sentiments\"].value_counts().rename(index=sentiment).plot(kind=\"barh\")\nvalidate_data[\"sentiments\"].value_counts().rename(index=sentiment).plot(kind=\"barh\")\ntest_data[\"sentiments\"].value_counts().rename(index=sentiment).plot(kind=\"barh\")\n\n\ncounter_tr = Counter(train_data[\"sentiments\"])\ncounter_val = Counter(validate_data[\"sentiments\"])\ncounter_ts = Counter(test_data[\"sentiments\"])\n\nprint(\"Training classes:\\n\") #number of each class in the training data\n\nfor k,v in counter_tr.items():\n\tper = v / len(train_data[\"sentiments\"]) * 100\n\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n# plot the distribution\npyplot.bar(counter_tr.keys(), counter_tr.values())\npyplot.show()\n\nprint(\"Validation classes:\\n\") #number of each class in the Validation data\n\nfor k,v in counter_val.items():\n\tper = v / len(validate_data[\"sentiments\"]) * 100\n\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n# plot the distribution\npyplot.bar(counter_val.keys(), counter_val.values())\npyplot.show()\n\nprint(\"Test classes:\\n\") #number of each class in the testing data\n\nfor k,v in counter_ts.items():\n\tper = v / len(test_data[\"sentiments\"]) * 100\n\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n# plot the distribution\npyplot.bar(counter_ts.keys(), counter_ts.values())\npyplot.show()","metadata":{"id":"gdkAOn0swsTN","outputId":"e43e2f39-9cc2-4e4e-dfb4-5f0dd1a04eba","execution":{"iopub.status.busy":"2022-03-05T22:43:39.455353Z","iopub.execute_input":"2022-03-05T22:43:39.455710Z","iopub.status.idle":"2022-03-05T22:43:40.004385Z","shell.execute_reply.started":"2022-03-05T22:43:39.455680Z","shell.execute_reply":"2022-03-05T22:43:40.003727Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"\n\n ⚡ *We can see that in the training data, the neutral and positive classes contains the majority of the data while the minority goes to the negative class. Therefore, it is important to have a balanced training set for our classifier. The simplest way to balance our training data is by using Undersampling technique which can be an easy way to balance our data.*\n","metadata":{"id":"qdcBVcQuzTNd"}},{"cell_type":"code","source":"# we have to balence our traning dataset \ntrain_data_0 = train_data[train_data['sentiments'] == 0].sample(frac=1)\ntrain_data_1 = train_data[train_data['sentiments'] == 1].sample(frac=1)\ntrain_data_2 = train_data[train_data['sentiments'] == 2].sample(frac=1)\n\n\n#  here we gonna use the min len of each class to equal our clasess in the traning data  \nmin_classes_size = min(len(train_data_0), len(train_data_1), len(train_data_2))\nprint(\"The minimum classes size is  :\",min_classes_size)\n","metadata":{"id":"AvEiSkb4COId","outputId":"cee84bf8-579a-452f-a4cc-3940c9d90cb3","execution":{"iopub.status.busy":"2022-03-05T22:43:40.005695Z","iopub.execute_input":"2022-03-05T22:43:40.005928Z","iopub.status.idle":"2022-03-05T22:43:40.023994Z","shell.execute_reply.started":"2022-03-05T22:43:40.005896Z","shell.execute_reply":"2022-03-05T22:43:40.023201Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# here we gonna compine the data with the min classes size to get balanced train data\nbalanced_train_data = pd.concat([train_data_0.head(min_classes_size), train_data_1.head(min_classes_size), train_data_2.head(min_classes_size)]).sample(frac=1)\nbalanced_train_data=balanced_train_data.reset_index(drop=True)\nprint(balanced_train_data)\n","metadata":{"id":"_7ALXzCoKttJ","outputId":"c0ffc494-2953-40e4-ac3d-497fb44bf7c1","execution":{"iopub.status.busy":"2022-03-05T22:43:40.122843Z","iopub.execute_input":"2022-03-05T22:43:40.123126Z","iopub.status.idle":"2022-03-05T22:43:40.137337Z","shell.execute_reply.started":"2022-03-05T22:43:40.123098Z","shell.execute_reply":"2022-03-05T22:43:40.136663Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"balanced_train_data['sentiments'].value_counts().head(10).plot.pie(autopct='%1.1f%%')","metadata":{"id":"1yE7SWUale6b","outputId":"7e97760f-6b95-464f-a728-7a99654c619b","execution":{"iopub.status.busy":"2022-03-05T22:43:40.349744Z","iopub.execute_input":"2022-03-05T22:43:40.350078Z","iopub.status.idle":"2022-03-05T22:43:40.469169Z","shell.execute_reply.started":"2022-03-05T22:43:40.350046Z","shell.execute_reply":"2022-03-05T22:43:40.468353Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(\"Classes values :\\n\" , balanced_train_data['sentiments'].value_counts())","metadata":{"id":"g9Rba6-vhcTB","outputId":"e214a390-d2a7-454f-9a4f-75ccd0101ece","execution":{"iopub.status.busy":"2022-03-05T22:43:40.548824Z","iopub.execute_input":"2022-03-05T22:43:40.549193Z","iopub.status.idle":"2022-03-05T22:43:40.556970Z","shell.execute_reply.started":"2022-03-05T22:43:40.549150Z","shell.execute_reply":"2022-03-05T22:43:40.556193Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Now Our traning data is balanced now😁\n\n\n\n","metadata":{"id":"w0XaAbqHDl7J"}},{"cell_type":"code","source":"# Lets explore the data by showing a random exampels \ndef data_samples(data):\n    for i in range(5):\n      num=random.randint(1, len(data))\n      print(f\"{data.name} [{num}]:\",data[\"news\"][num]) \nbalanced_train_data.name= \"train data\"\nvalidate_data.name= \"val data\"\ntest_data.name= \"test data\"\ndata_samples(balanced_train_data)\ndata_samples(validate_data)\ndata_samples(test_data)","metadata":{"id":"eR7OflbxFNL5","outputId":"4855c94e-3f13-4708-96e6-7183eebdaf5d","execution":{"iopub.status.busy":"2022-03-05T22:43:41.010316Z","iopub.execute_input":"2022-03-05T22:43:41.010532Z","iopub.status.idle":"2022-03-05T22:43:41.021727Z","shell.execute_reply.started":"2022-03-05T22:43:41.010507Z","shell.execute_reply":"2022-03-05T22:43:41.021045Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":">From the Random sampeles we can see that the datasets need alot of cleaning. before that lets see most used words in our datasets  ","metadata":{"id":"Gxaf9wQzeeRt"}},{"cell_type":"markdown","source":"#### **Wordcloud** 🔎\n\n> using word cloud to find the most used words for each type of sentiment","metadata":{"id":"j6E0fVlMKrBb"}},{"cell_type":"code","source":"# Import packages\n!pip install wordcloud\n!pip install stylecloud\n\n!wget https://i.pinimg.com/originals/f0/22/2b/f0222b5cb43dc6cb657debb7a2a3c6a9.jpg\n!wget https://static.vecteezy.com/system/resources/previews/000/379/905/non_2x/sad-emoji-vector-icon.jpg\n!wget https://i2.wp.com/files.123freevectors.com/wp-content/original/33815-black-neutral-face-emoji.jpg?w=600","metadata":{"id":"K7FHI74wDOAq","outputId":"6492ec95-027a-4ce7-f2ca-7105fffc9b1c","execution":{"iopub.status.busy":"2022-03-05T22:43:41.847090Z","iopub.execute_input":"2022-03-05T22:43:41.847523Z","iopub.status.idle":"2022-03-05T22:44:06.654886Z","shell.execute_reply.started":"2022-03-05T22:43:41.847492Z","shell.execute_reply":"2022-03-05T22:44:06.654104Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for Negative sentiments\n\noptimisticWords_tr = \" \".join([str(word) for word in balanced_train_data['news'][balanced_train_data['sentiments'] == 0]])\noptimisticWords_val = \" \".join([str(word) for word in validate_data['news'][validate_data['sentiments'] == 0]])\noptimisticWords_ts = \" \".join([str(word) for word in test_data['news'][test_data['sentiments'] == 0]])\n\nmask = np.array(Image.open('./sad-emoji-vector-icon.jpg'))\nword_cloud_tr = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_tr)\nword_cloud_val = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_val)\nword_cloud_ts = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_ts)\n\nplt.figure(1,figsize=(10,8))\nplt.imshow(word_cloud_tr)\nplt.title('The common negative sentiment words in the train data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(2,figsize=(10,8))\nplt.imshow(word_cloud_val)\nplt.title('The common negative sentiment words in the validation data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(3,figsize=(10,8))\nplt.imshow(word_cloud_ts)\nplt.title('The common negative sentiment words in the test data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.show()\n","metadata":{"id":"DUfIvUSGDXAY","outputId":"5bc76906-fb57-47cc-ae0d-e52bbf0cc43d","execution":{"iopub.status.busy":"2022-03-05T22:44:06.658125Z","iopub.execute_input":"2022-03-05T22:44:06.658334Z","iopub.status.idle":"2022-03-05T22:44:10.213925Z","shell.execute_reply.started":"2022-03-05T22:44:06.658309Z","shell.execute_reply":"2022-03-05T22:44:10.213220Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"balanced_train_data[\"news\"][2298]","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:44:10.215136Z","iopub.execute_input":"2022-03-05T22:44:10.217641Z","iopub.status.idle":"2022-03-05T22:44:10.223963Z","shell.execute_reply.started":"2022-03-05T22:44:10.217600Z","shell.execute_reply":"2022-03-05T22:44:10.223291Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for neutral sentiments\noptimisticWords_tr = \" \".join([str(word) for word in balanced_train_data['news'][balanced_train_data['sentiments'] == 1]])\noptimisticWords_val = \" \".join([str(word) for word in validate_data['news'][validate_data['sentiments'] == 1]])\noptimisticWords_ts = \" \".join([str(word) for word in test_data['news'][test_data['sentiments'] == 1]])\n\n\nmask = np.array(Image.open('./33815-black-neutral-face-emoji.jpg?w=600'))\nword_cloud_tr = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_tr)\nword_cloud_val = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_val)\nword_cloud_ts = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_ts)\n\nplt.figure(1,figsize=(10,8))\nplt.imshow(word_cloud_tr)\nplt.title('The common neutral sentiment words in the train data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(2,figsize=(10,8))\nplt.imshow(word_cloud_val)\nplt.title('The common neutral sentiment words in the validation data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(3,figsize=(10,8))\nplt.imshow(word_cloud_ts)\nplt.title('The common neutral sentiment words in the test data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.show()\n","metadata":{"id":"lqnJgfSUE0ep","outputId":"ae0b18a4-9f2c-4b45-91ea-a5f6e0fa7eef","execution":{"iopub.status.busy":"2022-03-05T22:44:10.226409Z","iopub.execute_input":"2022-03-05T22:44:10.226924Z","iopub.status.idle":"2022-03-05T22:44:14.729159Z","shell.execute_reply.started":"2022-03-05T22:44:10.226885Z","shell.execute_reply":"2022-03-05T22:44:14.728494Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for positive sentiments\n\noptimisticWords_tr = \" \".join([str(word) for word in balanced_train_data['news'][balanced_train_data['sentiments'] == 2]])\noptimisticWords_val = \" \".join([str(word) for word in validate_data['news'][validate_data['sentiments'] == 2]])\noptimisticWords_ts = \" \".join([str(word) for word in test_data['news'][test_data['sentiments'] == 2]])\n\nmask = np.array(Image.open('./f0222b5cb43dc6cb657debb7a2a3c6a9.jpg'))\nword_cloud_tr = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_tr)\nword_cloud_val = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_val)\nword_cloud_ts = WordCloud(width = 500, height = 500, background_color='black', mask=mask).generate(optimisticWords_ts)\n\nplt.figure(1,figsize=(10,8))\nplt.imshow(word_cloud_tr)\nplt.title('The common positive sentiment words in the train data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(2,figsize=(10,8))\nplt.imshow(word_cloud_val)\nplt.title('The common positive sentiment words in the validation data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.figure(3,figsize=(10,8))\nplt.imshow(word_cloud_ts)\nplt.title('The common positive sentiment words in the test data  ', \n          fontdict={'size': 22,  'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.show()","metadata":{"id":"PrjxmWsxJZAJ","outputId":"908c447c-6499-412f-b8d7-606aa33d2cf0","execution":{"iopub.status.busy":"2022-03-05T22:44:14.730574Z","iopub.execute_input":"2022-03-05T22:44:14.731025Z","iopub.status.idle":"2022-03-05T22:44:20.934812Z","shell.execute_reply.started":"2022-03-05T22:44:14.730989Z","shell.execute_reply":"2022-03-05T22:44:20.934047Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"\n**count the number of words in each news**\n\n\n","metadata":{"id":"93n57gdQg_eX"}},{"cell_type":"markdown","source":">Lets create new coulmn in each datasets contains the length of each news headline\n","metadata":{"id":"1llnTtwEFTie"}},{"cell_type":"code","source":"# Lets create new coulmn in each datasets contains the length of each news headline\ndef News_len(data):\n    news_len = []\n    for news in data:\n        news=str(news).split()\n        n_len = len(news)\n        news_len.append(n_len)\n    return news_len\n\n","metadata":{"id":"zBtIQtsL0Sol","execution":{"iopub.status.busy":"2022-03-05T22:44:20.936285Z","iopub.execute_input":"2022-03-05T22:44:20.936808Z","iopub.status.idle":"2022-03-05T22:44:20.941888Z","shell.execute_reply.started":"2022-03-05T22:44:20.936768Z","shell.execute_reply":"2022-03-05T22:44:20.941204Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"balanced_train_data['news_len']=News_len(balanced_train_data['news'])\nvalidate_data['news_len']=News_len(validate_data['news'])\ntest_data['news_len']=News_len(test_data['news'])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:44:20.943265Z","iopub.execute_input":"2022-03-05T22:44:20.943763Z","iopub.status.idle":"2022-03-05T22:44:21.016542Z","shell.execute_reply.started":"2022-03-05T22:44:20.943726Z","shell.execute_reply":"2022-03-05T22:44:21.015938Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(len(balanced_train_data['news_len']))\nprint(len(validate_data['news_len']))\nprint(len(test_data['news_len']))","metadata":{"id":"20HY8Ep87LXa","outputId":"6828107d-3477-4088-ab88-2fcdec3d098b","execution":{"iopub.status.busy":"2022-03-05T22:44:21.017759Z","iopub.execute_input":"2022-03-05T22:44:21.018000Z","iopub.status.idle":"2022-03-05T22:44:21.026282Z","shell.execute_reply.started":"2022-03-05T22:44:21.017967Z","shell.execute_reply":"2022-03-05T22:44:21.025600Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"> Lets see the number of words less then 20 in each news","metadata":{"id":"KvsXsnWJa0w3"}},{"cell_type":"code","source":"\nax = plt.subplots(figsize=(20,10), dpi=80)\nax = sns.countplot(x=\"news_len\", data=balanced_train_data[balanced_train_data['news_len']<20], order=range(1,20))\nplt.title('Training data with less than 20 words')\nplt.xlabel('Number of words')\nplt.ylabel('Count')\n\n\nfor p in ax.patches:\n        ax.annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+3), color='black', size=15)\nplt.show()","metadata":{"id":"S1QrDBE94BBX","outputId":"e984dfc4-47a2-49ec-afab-0b6c1fec4454","execution":{"iopub.status.busy":"2022-03-05T22:44:27.232753Z","iopub.execute_input":"2022-03-05T22:44:27.233046Z","iopub.status.idle":"2022-03-05T22:44:27.851647Z","shell.execute_reply.started":"2022-03-05T22:44:27.233015Z","shell.execute_reply":"2022-03-05T22:44:27.850543Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"ax = plt.subplots(figsize=(20,10), dpi=80)\nax = sns.countplot(x=\"news_len\", data=validate_data[validate_data['news_len']<20], order=range(1,20),palette='rainbow')\nplt.title('Val data with less than 20 words')\nplt.xlabel('Number of words')\nplt.ylabel('Count')\n\nfor p in ax.patches:\n        ax.annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+3), color='black', size=15)\nplt.show()","metadata":{"id":"N4rCxktcAB3L","outputId":"5c5664ff-14c8-4cae-ca4e-a2183a208ab1","execution":{"iopub.status.busy":"2022-03-05T22:44:27.853785Z","iopub.execute_input":"2022-03-05T22:44:27.854030Z","iopub.status.idle":"2022-03-05T22:44:28.266283Z","shell.execute_reply.started":"2022-03-05T22:44:27.853993Z","shell.execute_reply":"2022-03-05T22:44:28.265269Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"ax = plt.subplots(figsize=(20,10), dpi=80)\nax = sns.countplot(x=\"news_len\", data=test_data[test_data['news_len']<20], order=range(1,20),palette=['#432371',\"#FAAE7B\"])\n\nplt.title('test data with less than 20 words')\nplt.xlabel('Number of words')\nplt.ylabel('Count')\n\nfor p in ax.patches:\n        ax.annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+3), color='black', size=15)\nplt.show()","metadata":{"id":"cMF57UWacFhF","outputId":"9cb3a3bc-d995-4e53-c5a1-353556dcca1f","execution":{"iopub.status.busy":"2022-03-05T22:44:28.268161Z","iopub.execute_input":"2022-03-05T22:44:28.268444Z","iopub.status.idle":"2022-03-05T22:44:28.639957Z","shell.execute_reply.started":"2022-03-05T22:44:28.268409Z","shell.execute_reply":"2022-03-05T22:44:28.639131Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":">As we can see, few news headlines are less than 4 words, so this news is not useful to provide enough information.\nThese words may be in short form, so let's clean them up and then see.","metadata":{"id":"WJofoZ1rc6CX"}},{"cell_type":"markdown","source":"#### N-gram exploration ☘\n\n> Lets see unigrams(n=1),bigrams(n=2) and trigrams(n=3) comman words in the train dataset\n\n\n\n","metadata":{"id":"48JuulWgvSHu"}},{"cell_type":"code","source":"# get distribution of top unigrams,bigrams and trigrams \ndef get_ngrams(corpus, n_range = (1,1), n= None):\n    vec = CountVectorizer(ngram_range = n_range).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis = 0)\n    word_freq = [(word, sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n    word_freq = sorted(word_freq, key = lambda x: x[1], reverse = True)\n    return word_freq[:n]\n\n\nbalanced_train_data['news']=balanced_train_data['news'].apply(str)\nunigrams = get_ngrams(balanced_train_data['news'],(1,1),30)\nbigrams = get_ngrams(balanced_train_data['news'],(2,2),30)\ntrigrams =get_ngrams(balanced_train_data['news'],(3,3),30)\n\ndf_unigrams = pd.DataFrame(unigrams, columns = ['word','count'])\ndf_bigrams = pd.DataFrame(bigrams, columns = ['word','count'])\ndf_trigrams=pd.DataFrame(trigrams, columns = ['word','count'])\n\nplt.tight_layout()\nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,15))\nsns.barplot(x = 'count' , y = 'word', data = df_unigrams, orient = 'h',ax = ax1)\nax1.set_title('Top 30 most common unigrams in News')\nax1.spines[\"right\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.grid(False)\nsns.barplot(x = 'count' , y = 'word', data = df_bigrams, orient = 'h',ax = ax2)\nax2.set_title('Top 30 most common bigrams in News')\nax2.spines[\"right\"].set_visible(False)\nax2.spines[\"top\"].set_visible(False)\nax2.grid(False)   \nsns.barplot(x = 'count' , y = 'word', data = df_trigrams, orient = 'h',ax = ax3)\nax3.set_title('Top 30 most common trigrams in News')\nax3.spines[\"right\"].set_visible(False)\nax3.spines[\"top\"].set_visible(False)\nax3.grid(False)   ","metadata":{"id":"k8hcmmN79nhW","outputId":"551df7e6-62ed-4324-a24c-26d2f7b11c79","execution":{"iopub.status.busy":"2022-03-05T22:44:29.216553Z","iopub.execute_input":"2022-03-05T22:44:29.217160Z","iopub.status.idle":"2022-03-05T22:44:34.851856Z","shell.execute_reply.started":"2022-03-05T22:44:29.217124Z","shell.execute_reply":"2022-03-05T22:44:34.851158Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"\n\n> we can see that the top words in ngram are punctuations and stopwords ,so we need to clean them. \n\nBefore cleaning the text we gonna see how many words are covered in embedding in our datasets \n\n","metadata":{"id":"b7otS2ENy4fa"}},{"cell_type":"markdown","source":"## **Data Cleaning 🔎**","metadata":{"id":"ThubcT-Co1Dx"}},{"cell_type":"markdown","source":"#### **Getting the Glove Voctors 📥**\n\n> convert each word to its corresponding word embedding\n\n","metadata":{"id":"GgcmUWrAuqR2"}},{"cell_type":"markdown","source":"**Download Glove 27B 100d**","metadata":{"id":"F8ERfzF7tFwC"}},{"cell_type":"code","source":"#from google.colab import files\n#files.upload()\n# Then move kaggle.json into the folder where the API expects to find it.\n#!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json","metadata":{"id":"QqHoEhIDwPLf","outputId":"a167cd9e-3f77-4fd9-c767-775e10403b3d","execution":{"iopub.status.busy":"2022-03-05T22:44:34.853323Z","iopub.execute_input":"2022-03-05T22:44:34.853658Z","iopub.status.idle":"2022-03-05T22:44:35.183847Z","shell.execute_reply.started":"2022-03-05T22:44:34.853619Z","shell.execute_reply":"2022-03-05T22:44:35.182677Z"},"_kg_hide-output":true,"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#! kaggle datasets download -d robertyoung/glove-twitter-pickles-27b-25d-50d-100d-200d","metadata":{"id":"pl0TjGv7yb4e","outputId":"9aad018c-5765-4cd6-95f4-59e18347f34b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!unzip glove-twitter-pickles-27b-25d-50d-100d-200d.zip","metadata":{"id":"YAPTx_pJyi-1","outputId":"e07875dd-809f-4158-b3a3-e42317b00b2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create vocabulary and count of each vocabulary \n\nglove_embeddings= np.load('../input/glove-twitter-pickles-27b-25d-50d-100d-200d/glove.twitter.27B.100d.pkl',\n                          allow_pickle=True)  \ndef vocab_embaddied(news):\n  \n    news = news.apply(lambda s: s.split()).values      \n    vocabs = {}\n    \n    for news_ in news:\n        for word in news_:\n            try:\n                vocabs[word] += 1\n            except KeyError:\n                vocabs[word] = 1                \n    \n    covered={}\n    word_count={}\n    list_words={}\n    covered_num=0\n    num_list_words=0\n    \n    for word in vocabs:\n        try:\n            covered[word]=glove_embeddings[word]\n            covered_num+=vocabs[word]\n            word_count[word]=vocabs[word]\n        except:\n            list_words[word]=vocabs[word]\n            num_list_words+=list_words[word]\n    \n    vocab_coverage=len(covered)/len(vocabs)*100\n    #vocab_coverage=round(vocab_coverage,2)\n    text_coverage = covered_num/(covered_num+num_list_words)*100\n    #text_coverage=round(text_coverage,2)\n    sorted_uncovered_words=sorted(list_words.items(), key=operator.itemgetter(1))[::-1]\n    sorted_covered_words=sorted(word_count.items(), key=operator.itemgetter(1))[::-1]\n\n    return sorted_covered_words,sorted_uncovered_words, round(vocab_coverage,2), round(text_coverage,2)\n","metadata":{"id":"YrrS87gc0byn","execution":{"iopub.status.busy":"2022-03-05T22:45:08.662787Z","iopub.execute_input":"2022-03-05T22:45:08.663189Z","iopub.status.idle":"2022-03-05T22:45:18.543022Z","shell.execute_reply.started":"2022-03-05T22:45:08.663153Z","shell.execute_reply":"2022-03-05T22:45:18.542284Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_covered,train_uncovered,train_vocab_coverage,train_text_coverage=vocab_embaddied(balanced_train_data['news'])\nval_covered,val_uncovered,val_vocab_coverage,val_text_coverage=vocab_embaddied(validate_data['news'])\ntest_covered,test_uncovered, test_vocab_coverage, test_text_coverage = vocab_embaddied(test_data['news'])\nprint(f\"Glove embeddings cover {train_vocab_coverage}% of vocabulary and {train_text_coverage}% text in training set\")\nprint(f\"Glove embeddings cover {val_vocab_coverage}% of vocabulary and {val_text_coverage}% text in testing set\")\nprint(f\"Glove embeddings cover {test_vocab_coverage}% of vocabulary and {test_text_coverage}% text in testing set\")\n\n","metadata":{"id":"wzCzVcx10eYs","outputId":"be733dd6-d6eb-4843-dc80-82b39a1d7fd9","execution":{"iopub.status.busy":"2022-03-05T22:45:18.545606Z","iopub.execute_input":"2022-03-05T22:45:18.546131Z","iopub.status.idle":"2022-03-05T22:45:18.769501Z","shell.execute_reply.started":"2022-03-05T22:45:18.546093Z","shell.execute_reply":"2022-03-05T22:45:18.768636Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Lets see unconverd words in the vocab\nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,15))\n\nx=[]\ny=[]\nfor word,count in train_uncovered[:70]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y,y=x,ax = ax1)     \nax1.set_title('Uncovered words in the vocabularys in train data ')\n\n\nx=[]\ny=[]\nfor word,count in val_uncovered[:70]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nplt.figure(figsize=(15,8))\nsns.barplot(x=y,y=x,ax = ax2)     \nax2.set_title('Uncovered words in the vocabularys in val data')\n\nx=[]\ny=[]\nfor word,count in test_uncovered[:70]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nplt.figure(figsize=(15,8))\nsns.barplot(x=y,y=x,ax = ax3)     \nax3.set_title('Uncovered words in the vocabularys in test data')\n\n\n","metadata":{"id":"lFs447aYNVHi","outputId":"004ae970-9d2a-466a-e6ff-b8ac040d1d2a","execution":{"iopub.status.busy":"2022-03-05T22:45:24.939937Z","iopub.execute_input":"2022-03-05T22:45:24.940189Z","iopub.status.idle":"2022-03-05T22:45:28.099032Z","shell.execute_reply.started":"2022-03-05T22:45:24.940160Z","shell.execute_reply":"2022-03-05T22:45:28.098424Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**💡 we see a group of words that are not covered because they require cleaning like informal or abbreviated words , here are some of these words:**\n\n▶ *1q* --> first quarter\n\n▶ *2q* --> second quarter\n\n▶ *3q*--> third quarter \n\n▶ *4q*--> fourth quarter\n\n▶ *1mdb* --> Malaysian strategic development company\n\n▶ *alliancedbs* --> research company \n\n▶ *ge14* --> Malaysia's 14th General Election\n\n▶ *Covid-19* --> corona\n\n▶ *hlib* -->  Hong Leong Investment Bank \n\n▶ *fy17* --> the financial year of the Group ended 30 April 2017\n\n▶ *myeg* -->Malaysian Electronic Government\n\n......\n\n\n\n\n**So Lets include these words in our cleaning process :)**\n\n","metadata":{"id":"MLrZPM6mR9NA"}},{"cell_type":"markdown","source":"# Text Cleaning📝\nwe will clean the data from:\n\n⏩Removing HTML tags\n⏩Removing urls\n⏩Removing punctuations\n","metadata":{"id":"jTjIKXqEEcpQ"}},{"cell_type":"code","source":"\ndef Clean_news(news):\n    #informal abbreviations\n    news = news.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n    news = re.sub(r\"rfp\", \"Registered Financial Planner\", news)    \n    news = re.sub(r\"mou\", \"memorandum of understanding\", news)  \n    news = re.sub(r\"ups\", \"upgrade\", news)         \n    news = re.sub(r\"y-o-y\", \"Year over year\", news)    \n    news = re.sub(r\"1q\", \"first quarter\", news)\n    news = re.sub(r\"2q\", \"second quarter\", news)\n    news = re.sub(r\"3q\", \"third quarter\", news)\n    news = re.sub(r\"4q\", \"fourth quarter\", news)\n    news = re.sub(r\"1mdb\", \"malaysian strategic development company\", news)\n    news = re.sub(r\"alliancedbs\", \"research company\", news)\n    news = re.sub(r\"ge14\", \"The fourteenth general election in Malaysia\", news)\n    news = re.sub(r\"Covid-19\", \"covid\", news)\n    news = re.sub(r\"hlib\", \"Hong Leong Investment Bank\", news)   \n    news = re.sub(r\"fy16\", \"the fiscal year commencing on 1 April 2016 and ending on 31 March 2017\", news)\n    news = re.sub(r\"fy17\", \"the financial year of the Group ended 30 April 2017\", news)\n    news = re.sub(r\"fy18\", \"the fiscal year commencing on 1 April 2018 and ending on 31 March 2019\", news)\n    news = re.sub(r\"brexit\", \"British exit\", news)\n    news = re.sub(r\"midf\", \"Malaysia Industrial Development Finance\", news)\n    news = re.sub(r\"myeg\", \"Malaysian Electronic Government\", news)\n    news = re.sub(r\"mrcb\", \"Magnetic resonance cholangiopancreatography\", news)\n    news = re.sub(r\"sapura\", \"Malaysian integrated oil and gas services compan\", news)\n    news = re.sub(r\"covid-19\", \"coronavirus\", news)\n    news = re.sub(r\"covid\", \"coronavirus\", news)\n    news = re.sub(r\"boustead\", \"Malaysian corporation\", news)\n    news = re.sub(r\"drbhicom\", \"automotive industry company\", news)\n    news = re.sub(r\"sapurakencana \", \"Malaysian integrated oil and gas services company\", news)\n    news = re.sub(r\"gamuda\", \"construction engineering company\", news)\n    news = re.sub(r\"glomac\", \"Real estate company\", news)\n    news = re.sub(r\"malaysia's\", \"Malaysian\", news)\n    news = re.sub(r\"â€“\", \"\", news)\n    news = re.sub(r\"quarterthe\", \"quarter the\", news)\n    news = re.sub(r\"cholangiopancreatography\", \"diagnostic technique\", news)\n    news = re.sub(r\"compankencan\", \"australian Bank\", news)\n    news = re.sub(r\"off-market\", \"off market\", news)\n    news = re.sub(r\"westports\", \"Marine cargo handling company\", news)\n    news = re.sub(r\"fullyear\", \"full year\", news)\n    news = re.sub(r\"uschina\", \"us china\", news)\n    news = re.sub(r\"ecoworld\", \"Eco world development company\", news)\n    news = re.sub(r\"fbm klci\", \"FTSE Bursa malaysia Kuala Lumpur Composite Index\", news)\n    news = re.sub(r\"ecrl\", \"East Coast Rail Line\", news)\n    news = re.sub(r\"lossmaking\", \"loss making\", news)\n    news = re.sub(r\"tieup\", \"tie up\", news)\n    news = re.sub(r\"doubledigit\", \"double digit\", news)\n    news = re.sub(r\"klci\", \"kuala lumpur Composite Index\", news)\n    news = re.sub(r\"mahb\", \"Malaysia Airports\", news)\n\n\n\n    # Remove numbers from news'\n    news = re.sub(r'\\d+',' ', news)\n\n    # Removing everthing other than alphabets\n    news = re.sub(r'@[A-Za-z0-9_]+','',news)\n    news = re.sub(r'#','',news)\n    news = re.sub(r' — ','',news)\n    news = re.sub(r'RT : ','',news)\n    # Removing whitespace characters\n\n    #news = re.sub(r'\\s',' ',news)\n    #news = re.sub(r' +',' ',news)\n    #urls\n    news= re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\", \"url\", news)           \n    # Special characters\n    news=re.sub('\\x91The','The',news)\n    news=re.sub('\\x97','',news)\n    news=re.sub('\\x84The','The',news)\n    news = re.sub(r\"\\x89Û_\", \"\", news)\n    news = re.sub(r\"\\x89ÛÒ\", \"\", news)\n    news = re.sub(r\"\\x89ÛÓ\", \"\", news)\n    # remove concated words\n    news = re.sub(r\"\\x89ÛÏWhen\", \"When\", news)\n    news = re.sub(r\"\\x89ÛÏ\", \"\", news)\n    news = re.sub(r\"China\\x89Ûªs\", \"China's\", news)\n    news = re.sub(r\"let\\x89Ûªs\", \"let's\", news)\n    news = re.sub(r\"\\x89Û÷\", \"\", news)\n    news = re.sub(r\"\\x89Ûª\", \"\", news)\n    news = re.sub(r\"\\x89Û\\x9d\", \"\", news)\n    news = re.sub(r\"å_\", \"\", news)\n    news = re.sub(r\"\\x89Û¢\", \"\", news)\n    news = re.sub(r\"\\x89Û¢åÊ\", \"\", news)\n    news = re.sub(r\"fromåÊwounds\", \"from wounds\", news)\n    news = re.sub(r\"åÊ\", \"\", news)\n    news = re.sub(r\"åÈ\", \"\", news)\n    news = re.sub(r\"JapÌ_n\", \"Japan\", news)    \n    news = re.sub(r\"Ì©\", \"e\", news)\n    news = re.sub(r\"å¨\", \"\", news)\n    news = re.sub(r\"SuruÌ¤\", \"Suruc\", news)\n    news = re.sub(r\"åÇ\", \"\", news)\n    news = re.sub(r\"å£3million\", \"3 million\", news)\n    news = re.sub(r\"åÀ\", \"\", news)\n    news = re.sub(r\"he's\", \"he is\", news)\n    news = re.sub(r\"there's\", \"there is\", news)\n    news = re.sub(r\"We're\", \"We are\", news)\n    news = re.sub(r\"That's\", \"That is\", news)\n    news = re.sub(r\"won't\", \"will not\", news)\n    news = re.sub(r\"they're\", \"they are\", news)\n    news = re.sub(r\"Can't\", \"Cannot\", news)\n    news = re.sub(r\"wasn't\", \"was not\", news)\n    news = re.sub(r\"don\\x89Ûªt\", \"do not\", news)\n    news = re.sub(r\"aren't\", \"are not\", news)\n    news = re.sub(r\"isn't\", \"is not\", news)\n    news = re.sub(r\"What's\", \"What is\", news)\n    news = re.sub(r\"haven't\", \"have not\", news)\n    news = re.sub(r\"hasn't\", \"has not\", news)\n    news = re.sub(r\"There's\", \"There is\", news)\n    news = re.sub(r\"He's\", \"He is\", news)\n    news = re.sub(r\"It's\", \"It is\", news)\n    news = re.sub(r\"You're\", \"You are\", news)\n    news = re.sub(r\"I'M\", \"I am\", news)\n    news = re.sub(r\"shouldn't\", \"should not\", news)\n    news = re.sub(r\"wouldn't\", \"would not\", news)\n    news = re.sub(r\"i'm\", \"I am\", news)\n    news = re.sub(r\"I\\x89Ûªm\", \"I am\", news)\n    news = re.sub(r\"I'm\", \"I am\", news)\n    news = re.sub(r\"Isn't\", \"is not\", news)\n    news = re.sub(r\"Here's\", \"Here is\", news)\n    news = re.sub(r\"you've\", \"you have\", news)\n    news = re.sub(r\"you\\x89Ûªve\", \"you have\", news)\n    news = re.sub(r\"we're\", \"we are\", news)\n    news = re.sub(r\"what's\", \"what is\", news)\n    news = re.sub(r\"couldn't\", \"could not\", news)\n    news = re.sub(r\"we've\", \"we have\", news)\n    news = re.sub(r\"it\\x89Ûªs\", \"it is\", news)\n    news = re.sub(r\"doesn\\x89Ûªt\", \"does not\", news)\n    news = re.sub(r\"It\\x89Ûªs\", \"It is\", news)\n    news = re.sub(r\"Here\\x89Ûªs\", \"Here is\", news)\n    news = re.sub(r\"who's\", \"who is\", news)\n    news = re.sub(r\"I\\x89Ûªve\", \"I have\", news)\n    news = re.sub(r\"y'all\", \"you all\", news)\n    news = re.sub(r\"can\\x89Ûªt\", \"cannot\", news)\n    news = re.sub(r\"would've\", \"would have\", news)\n    news = re.sub(r\"it'll\", \"it will\", news)\n    news = re.sub(r\"we'll\", \"we will\", news)\n    news = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", news)\n    news = re.sub(r\"We've\", \"We have\", news)\n    news = re.sub(r\"he'll\", \"he will\", news)\n    news = re.sub(r\"Y'all\", \"You all\", news)\n    news = re.sub(r\"Weren't\", \"Were not\", news)\n    news = re.sub(r\"Didn't\", \"Did not\", news)\n    news = re.sub(r\"they'll\", \"they will\", news)\n    news = re.sub(r\"they'd\", \"they would\", news)\n    news = re.sub(r\"DON'T\", \"DO NOT\", news)\n    news = re.sub(r\"That\\x89Ûªs\", \"That is\", news)\n    news = re.sub(r\"they've\", \"they have\", news)\n    news = re.sub(r\"i'd\", \"I would\", news)\n    news = re.sub(r\"should've\", \"should have\", news)\n    news = re.sub(r\"You\\x89Ûªre\", \"You are\", news)\n    news = re.sub(r\"where's\", \"where is\", news)\n    news = re.sub(r\"Don\\x89Ûªt\", \"Do not\", news)\n    news = re.sub(r\"we'd\", \"we would\", news)\n    news = re.sub(r\"i'll\", \"I will\", news)\n    news = re.sub(r\"weren't\", \"were not\", news)\n    news = re.sub(r\"They're\", \"They are\", news)\n    news = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", news)\n    news = re.sub(r\"you\\x89Ûªll\", \"you will\", news)\n    news = re.sub(r\"I\\x89Ûªd\", \"I would\", news)\n    news = re.sub(r\"let's\", \"let us\", news)\n    news = re.sub(r\"it's\", \"it is\", news)\n    news = re.sub(r\"can't\", \"cannot\", news)\n    news = re.sub(r\"don't\", \"do not\", news)\n    news = re.sub(r\"you're\", \"you are\", news)\n    news = re.sub(r\"i've\", \"I have\", news)\n    news = re.sub(r\"that's\", \"that is\", news)\n    news = re.sub(r\"i'll\", \"I will\", news)\n    news = re.sub(r\"doesn't\", \"does not\", news)\n    news = re.sub(r\"i'd\", \"I would\", news)\n    news = re.sub(r\"didn't\", \"did not\", news)\n    news = re.sub(r\"ain't\", \"am not\", news)\n    news = re.sub(r\"you'll\", \"you will\", news)\n    news = re.sub(r\"I've\", \"I have\", news)\n    news = re.sub(r\"Don't\", \"do not\", news)\n    news = re.sub(r\"I'll\", \"I will\", news)\n    news = re.sub(r\"I'd\", \"I would\", news)\n    news = re.sub(r\"Let's\", \"Let us\", news)\n    news = re.sub(r\"you'd\", \"You would\", news)\n    news = re.sub(r\"It's\", \"It is\", news)\n    news = re.sub(r\"Ain't\", \"am not\", news)\n    news = re.sub(r\"Haven't\", \"Have not\", news)\n    news = re.sub(r\"Could've\", \"Could have\", news)\n    news = re.sub(r\"youve\", \"you have\", news)  \n    news = re.sub(r\"donå«t\", \"do not\", news)        \n    news = re.sub(r\"&gt;\", \">\", news)\n    news = re.sub(r\"&lt;\", \"<\", news)\n    news = re.sub(r\"&amp;\", \"&\", news)  \n    news = re.sub(r\"w/e\", \"whatever\", news)\n    news = re.sub(r\"w/\", \"with\", news)\n    news = re.sub(r\"recentlu\", \"recently\", news)\n    news = re.sub(r\"Ph0tos\", \"Photos\", news)\n    news = re.sub(r\"amirite\", \"am I right\", news)\n    news = re.sub(r\"exp0sed\", \"exposed\", news)\n    news = re.sub(r\"<3\", \"love\", news)\n    news = re.sub(r\"amageddon\", \"armageddon\", news)\n    news = re.sub(r\"Trfc\", \"Traffic\", news)\n    news = re.sub(r\"WindStorm\", \"Wind Storm\", news)\n    news = re.sub(r\"lmao\", \"laughing my ass off\", news)   \n    news = re.sub(r\"TRAUMATISED\", \"traumatized\", news)\n    news = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", news)\n     # remove emojis\n    news = re.sub(emoji.get_emoji_regexp(), r\"\", news)\n    news = news.replace('...', ' ... ')\n    if '...' not in news:\n        news = news.replace('..', ' ... ')      \n        # Remove single char\n    #news = re.sub(r'\\b\\w{1,1}\\b', '', news)    \n    #news = news.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n\n    return news \n   # punctuations and special characters\ndef punctuations_removel(news):\n    table=str.maketrans('','',string.punctuation)\n    return news.translate(table)\n\ndef remove_stopwords(news):\n    news = [word.lower() for word in news.split() if word.lower() not in stop]\n    return \" \".join(news)\n\n\n\n","metadata":{"id":"TMUMQF6-On2b","execution":{"iopub.status.busy":"2022-03-05T22:45:37.521847Z","iopub.execute_input":"2022-03-05T22:45:37.522288Z","iopub.status.idle":"2022-03-05T22:45:37.578106Z","shell.execute_reply.started":"2022-03-05T22:45:37.522250Z","shell.execute_reply":"2022-03-05T22:45:37.577419Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# test the functions \ntext=\"World the😁\"\nprint(Clean_news(text))\ntext2=\"hi ,mo\"\nprint(punctuations_removel(text2))","metadata":{"id":"8Gg1umdL1f4g","outputId":"ace4013e-2495-4f39-bf34-605334323ca3","execution":{"iopub.status.busy":"2022-03-05T22:45:37.983769Z","iopub.execute_input":"2022-03-05T22:45:37.983990Z","iopub.status.idle":"2022-03-05T22:45:38.083396Z","shell.execute_reply.started":"2022-03-05T22:45:37.983966Z","shell.execute_reply":"2022-03-05T22:45:38.082658Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# create a new coulmn for clean news\nbalanced_train_data['cleaned_News']=balanced_train_data['news'].apply(Clean_news).apply(punctuations_removel).apply(remove_stopwords)\nvalidate_data['cleaned_News']=validate_data['news'].apply(Clean_news).apply(punctuations_removel).apply(remove_stopwords)\ntest_data['cleaned_News']=test_data['news'].apply(Clean_news).apply(punctuations_removel).apply(remove_stopwords)\n","metadata":{"id":"JEx5HLnpihFY","execution":{"iopub.status.busy":"2022-03-05T22:45:38.297077Z","iopub.execute_input":"2022-03-05T22:45:38.297741Z","iopub.status.idle":"2022-03-05T22:46:10.321925Z","shell.execute_reply.started":"2022-03-05T22:45:38.297702Z","shell.execute_reply":"2022-03-05T22:46:10.321191Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(len(balanced_train_data['cleaned_News']))\nprint(len(validate_data))\nprint(len(test_data))","metadata":{"id":"W1WKcsPmimz-","outputId":"f21016ce-d47f-44ca-d6b9-4dc4e604c79b","execution":{"iopub.status.busy":"2022-03-05T22:46:10.324461Z","iopub.execute_input":"2022-03-05T22:46:10.324653Z","iopub.status.idle":"2022-03-05T22:46:10.331957Z","shell.execute_reply.started":"2022-03-05T22:46:10.324629Z","shell.execute_reply":"2022-03-05T22:46:10.331278Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# compare a random test news \nprint(\"Before cleaning : \",balanced_train_data[\"news\"][22])\nprint(\"After cleaning : \",balanced_train_data[\"cleaned_News\"][22])","metadata":{"id":"ae129hSzrWE9","outputId":"f5250a3f-233e-4f09-d38f-b5620114fd3d","execution":{"iopub.status.busy":"2022-03-05T22:46:10.333208Z","iopub.execute_input":"2022-03-05T22:46:10.334053Z","iopub.status.idle":"2022-03-05T22:46:10.342300Z","shell.execute_reply.started":"2022-03-05T22:46:10.334015Z","shell.execute_reply":"2022-03-05T22:46:10.341539Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Lets check if we have blanks in all datasets \nprint(\"Training: \\n\", balanced_train_data.loc[balanced_train_data[\"cleaned_News\"] == \"\"]) \nprint(\"Validation: \\n\", validate_data.loc[validate_data[\"cleaned_News\"] == \"\"]) \nprint(\"Testing: \\n\", test_data.loc[test_data[\"cleaned_News\"] == \"\"]) \n","metadata":{"id":"u3kXu4zgtaIs","outputId":"6081c415-e3f3-493b-cda6-4bc2d53b11e3","execution":{"iopub.status.busy":"2022-03-05T22:46:10.345611Z","iopub.execute_input":"2022-03-05T22:46:10.346104Z","iopub.status.idle":"2022-03-05T22:46:10.370224Z","shell.execute_reply.started":"2022-03-05T22:46:10.346063Z","shell.execute_reply":"2022-03-05T22:46:10.369553Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"balanced_train_data['clean_news_len']=News_len(balanced_train_data['cleaned_News'])\nvalidate_data['clean_news_len']=News_len(validate_data['cleaned_News'])\ntest_data['clean_news_len']=News_len(test_data['cleaned_News'])","metadata":{"id":"wQ-8HbWtZRDU","execution":{"iopub.status.busy":"2022-03-05T22:46:10.371664Z","iopub.execute_input":"2022-03-05T22:46:10.371841Z","iopub.status.idle":"2022-03-05T22:46:10.434923Z","shell.execute_reply.started":"2022-03-05T22:46:10.371819Z","shell.execute_reply":"2022-03-05T22:46:10.434295Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":">Lets see the number of words after cleaning ","metadata":{"id":"Pav-rqVFX7Ix"}},{"cell_type":"code","source":"fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(25,10))\nsns.countplot(x=\"news_len\", data=balanced_train_data[balanced_train_data['news_len']<20], order=range(1,20),ax=ax[0],palette=\"icefire\")\nplt.xlabel('Number of words')\nplt.ylabel('Count')\nsns.countplot(x=\"clean_news_len\", data=balanced_train_data[balanced_train_data['clean_news_len']<20], order=range(1,20),ax=ax[1],palette=\"icefire\")\nfor p in ax[0].patches:\n        ax[0].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+4), color='black', size=15)\n\nfor p in ax[1].patches:\n        ax[1].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+4), color='black', size=15)\n\nplt.show()\n","metadata":{"id":"3--LeccTX1X3","outputId":"f7a9b7e5-3bd4-42d7-9041-7366ed37d046","execution":{"iopub.status.busy":"2022-03-05T22:46:10.436122Z","iopub.execute_input":"2022-03-05T22:46:10.436590Z","iopub.status.idle":"2022-03-05T22:46:11.099290Z","shell.execute_reply.started":"2022-03-05T22:46:10.436554Z","shell.execute_reply":"2022-03-05T22:46:11.098645Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(25,10))\nsns.countplot(x=\"news_len\", data=validate_data[validate_data['news_len']<20], order=range(1,20),ax=ax[0],palette=\"coolwarm\")\nplt.xlabel('Number of words')\nplt.ylabel('Count')\nsns.countplot(x=\"clean_news_len\", data=validate_data[validate_data['clean_news_len']<20], order=range(1,20),ax=ax[1],palette=\"coolwarm\")\nprint(\"Val Data\")\nfor p in ax[0].patches:\n        ax[0].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+3), color='black', size=15)\n\nfor p in ax[1].patches:\n        ax[1].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+3), color='black', size=15)\n\nplt.show()","metadata":{"id":"CXgHB2R-0uaP","outputId":"3efed5ed-082c-4bea-8c91-aa2d50837abf","execution":{"iopub.status.busy":"2022-03-05T22:46:11.100520Z","iopub.execute_input":"2022-03-05T22:46:11.100926Z","iopub.status.idle":"2022-03-05T22:46:11.729278Z","shell.execute_reply.started":"2022-03-05T22:46:11.100886Z","shell.execute_reply":"2022-03-05T22:46:11.727436Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(25,10))\nsns.countplot(x=\"news_len\", data=test_data[test_data['news_len']<20], order=range(1,20),ax=ax[0])\nplt.xlabel('Number of words')\nplt.ylabel('Count')\nsns.countplot(x=\"clean_news_len\", data=test_data[test_data['clean_news_len']<20], order=range(1,20),ax=ax[1])\nprint(\"Val Data\")\nfor p in ax[0].patches:\n        ax[0].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+4), color='black', size=15)\n\nfor p in ax[1].patches:\n        ax[1].annotate(f'\\n{p.get_height()}', (p.get_x(), p.get_height()+4), color='black', size=15)\n\nplt.show()","metadata":{"id":"XmnfjBnk14lO","outputId":"ccb85edc-6c5c-4edc-9f98-1201ce50f46a","execution":{"iopub.status.busy":"2022-03-05T22:46:15.793233Z","iopub.execute_input":"2022-03-05T22:46:15.793846Z","iopub.status.idle":"2022-03-05T22:46:16.595820Z","shell.execute_reply.started":"2022-03-05T22:46:15.793809Z","shell.execute_reply":"2022-03-05T22:46:16.595000Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":">  We can see that we have a lot of news with less than 5 words, so we are going to drop this news. \n\n\n","metadata":{"id":"Gn-ht47buNai"}},{"cell_type":"code","source":"print(len(balanced_train_data))\nprint(len(validate_data))\nprint(len(test_data))\n\ntraindata = balanced_train_data[balanced_train_data['clean_news_len'] > 4].reset_index(drop=True)\nvaldata = validate_data[validate_data['clean_news_len'] > 4].reset_index(drop=True)\ntestdata = test_data[test_data['clean_news_len'] > 4].reset_index(drop=True)\n\nprint(len(traindata))\nprint(len(valdata))\nprint(len(testdata))","metadata":{"id":"yXgPoO0_njRg","outputId":"fc865626-8c20-4940-b0c3-fd71278f5759","execution":{"iopub.status.busy":"2022-03-05T22:46:16.597623Z","iopub.execute_input":"2022-03-05T22:46:16.597892Z","iopub.status.idle":"2022-03-05T22:46:16.615340Z","shell.execute_reply.started":"2022-03-05T22:46:16.597855Z","shell.execute_reply":"2022-03-05T22:46:16.614559Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"traindata","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:46:17.076951Z","iopub.execute_input":"2022-03-05T22:46:17.077157Z","iopub.status.idle":"2022-03-05T22:46:17.094730Z","shell.execute_reply.started":"2022-03-05T22:46:17.077132Z","shell.execute_reply":"2022-03-05T22:46:17.093979Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#Lets get only the clean news \ntrain_clean_news = traindata['cleaned_News']\ntest_clean_news = testdata[\"cleaned_News\"]\nval_clean_news = valdata[\"cleaned_News\"]\nprint('train data \\n',train_clean_news[:20])\nprint('test data \\n',test_clean_news[:20])\nprint('val data \\n',val_clean_news[:20])","metadata":{"id":"038RRGZt28gc","outputId":"f146d23e-d49c-4ff0-ba80-288e8f3ac312","execution":{"iopub.status.busy":"2022-03-05T22:46:17.925647Z","iopub.execute_input":"2022-03-05T22:46:17.926294Z","iopub.status.idle":"2022-03-05T22:46:17.935694Z","shell.execute_reply.started":"2022-03-05T22:46:17.926255Z","shell.execute_reply":"2022-03-05T22:46:17.934943Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":">Now after we get the datasets cleaned , lets see the vocabulary covers: ","metadata":{"id":"f0bmY4GnBFiP"}},{"cell_type":"code","source":"train_covered,train_oov,train_vocab_coverage,train_text_coverage=vocab_embaddied(train_clean_news)\nval_covered,val_oov,val_vocab_coverage,val_text_coverage=vocab_embaddied(val_clean_news)\ntest_covered,test_oov, test_vocab_coverage, test_text_coverage = vocab_embaddied(test_clean_news)\n\nprint(f\"Glove embeddings cover {train_vocab_coverage}% of vocabulary and {train_text_coverage}% text in training data\")\nprint(f\"Glove embeddings cover {val_vocab_coverage}% of vocabulary and {val_text_coverage}% text in validation data\")\nprint(f\"Glove embeddings cover {test_vocab_coverage}% of vocabulary and {test_text_coverage}% text in testing data\")\n","metadata":{"id":"EsI8Y-Jz1D8I","outputId":"530230ca-0d35-47fb-80ea-0b31f962e7da","execution":{"iopub.status.busy":"2022-03-05T22:46:18.866239Z","iopub.execute_input":"2022-03-05T22:46:18.866783Z","iopub.status.idle":"2022-03-05T22:46:19.058766Z","shell.execute_reply.started":"2022-03-05T22:46:18.866746Z","shell.execute_reply":"2022-03-05T22:46:19.057903Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Uncovered words after cleaning\nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(20,15))\n\nx=[]\ny=[]\nfor word,count in train_oov[:50]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y,y=x,ax = ax1)     \nax1.set_title('Uncovered words in the vocabularys in train data ')\n\n\nx=[]\ny=[]\nfor word,count in val_oov[:50]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nplt.figure(figsize=(15,8))\nsns.barplot(x=y,y=x,ax = ax2)     \nax2.set_title('Uncovered words in the vocabularys in val data')\n\nx=[]\ny=[]\nfor word,count in test_oov[:50]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nplt.figure(figsize=(15,8))\nsns.barplot(x=y,y=x,ax = ax3)     \nax3.set_title('Uncovered words in the vocabularys in test data')\n\n\n","metadata":{"id":"rc658o2TYRbh","outputId":"271bc074-736c-4cdb-c9a1-6d1631cf6281","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T22:46:19.633804Z","iopub.execute_input":"2022-03-05T22:46:19.634363Z","iopub.status.idle":"2022-03-05T22:46:22.034501Z","shell.execute_reply.started":"2022-03-05T22:46:19.634329Z","shell.execute_reply":"2022-03-05T22:46:22.033817Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"Almost all the words not covered in the vocabulary are company names, so we'll keep them.","metadata":{"id":"-zmoHtmxW0OO"}},{"cell_type":"markdown","source":"\n> **Let's see the most common words used in train dataset after cleaning** \n\n\n\n","metadata":{"id":"PADO7GLMvMn4"}},{"cell_type":"code","source":"tr_words=[]\ntr_count=[]\n\ni=1\nfor word,count in train_covered:\n  tr_words.append(word)\n  tr_count.append(count)\n  i+=1\n  if(i==50):\n     break\n\nplt.figure(figsize=(20,10))\nsns.barplot(x=tr_count,y=tr_words).set_title('50 most used words in the training data')\nplt.grid()","metadata":{"id":"sF0JBOPIDFeA","outputId":"decb9150-9f68-4abb-a640-dc9919df3eb0","execution":{"iopub.status.busy":"2022-03-05T22:46:27.183268Z","iopub.execute_input":"2022-03-05T22:46:27.183991Z","iopub.status.idle":"2022-03-05T22:46:27.855953Z","shell.execute_reply.started":"2022-03-05T22:46:27.183951Z","shell.execute_reply":"2022-03-05T22:46:27.855268Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Converting Sentences into Vectores (Embedding Layer output)🚧\n\nthe first thing we have to do before we can build a model is to convert the text to vectores .in this project we will be using BiLSTM Model and we won't be using an embedding layer, so we will create the output that should come from the Embedding layer.","metadata":{"id":"GOuzFt6e3s-R"}},{"cell_type":"markdown","source":"> First Let's see the max number of words in each news\n\n","metadata":{"id":"i5XFZ7JoUZxo"}},{"cell_type":"code","source":"print('Largest sentence has {} words'.format(traindata['clean_news_len'].max()))","metadata":{"id":"vhvxSNyIZP6X","outputId":"5e282897-95d3-4259-f82c-8ab7320a5eb5","execution":{"iopub.status.busy":"2022-03-05T22:46:31.715202Z","iopub.execute_input":"2022-03-05T22:46:31.715477Z","iopub.status.idle":"2022-03-05T22:46:31.720813Z","shell.execute_reply.started":"2022-03-05T22:46:31.715446Z","shell.execute_reply":"2022-03-05T22:46:31.719964Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"The majority of the texts appear to be fewer than 64 words.\nAs a result, determining the maximum length of sequences to be 64 is a good compromise between data loss and computational complexity.","metadata":{"id":"H8xw7gf-XYUX"}},{"cell_type":"code","source":"def embedding_output(x):\n    maxlen = traindata['clean_news_len'].max()     \n    embedding_dim = 100\n    emb_output= np.zeros((x.shape[0],maxlen,embedding_dim))\n    for sentence in range(x.shape[0]):\n      x[sentence]= x[sentence].split() # split a sentence to words \n      for word in range(len(x[sentence])): # every word in the sentence \n            try :\n                emb_output[sentence][word] = glove_embeddings[x[sentence][word].lower()]\n            except :\n                emb_output[sentence][word]=np.zeros((100,))\n    return emb_output ","metadata":{"id":"5HE8qArxv_Ka","execution":{"iopub.status.busy":"2022-03-05T22:47:13.347939Z","iopub.execute_input":"2022-03-05T22:47:13.348208Z","iopub.status.idle":"2022-03-05T22:47:13.354625Z","shell.execute_reply.started":"2022-03-05T22:47:13.348178Z","shell.execute_reply":"2022-03-05T22:47:13.353867Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_train=embedding_output(train_clean_news)\nembedding_matrix_test=embedding_output(test_clean_news)\nembedding_matrix_val=embedding_output(val_clean_news)\n\n# shape of train matrix is a 3d tensor\nprint(embedding_matrix_train.shape)\nprint(embedding_matrix_test.shape)\nprint(embedding_matrix_val.shape)","metadata":{"id":"O3kIGtCH4T6l","outputId":"dbf8ac7b-adfc-4719-d749-70a37d8bc2ef","execution":{"iopub.status.busy":"2022-03-05T22:47:16.918835Z","iopub.execute_input":"2022-03-05T22:47:16.920588Z","iopub.status.idle":"2022-03-05T22:47:36.995475Z","shell.execute_reply.started":"2022-03-05T22:47:16.920529Z","shell.execute_reply":"2022-03-05T22:47:36.993740Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# We have to convert the labels to one hot vector\ntrain_labels= to_categorical(traindata[\"sentiments\"],num_classes=3)\ntest_labels= to_categorical(testdata[\"sentiments\"],num_classes=3)\nval_labels= to_categorical(valdata[\"sentiments\"],num_classes=3)\nprint(train_labels.shape)\nprint(test_labels.shape)\nprint(val_labels.shape)","metadata":{"id":"3nGZ-sdj4tz9","outputId":"a335dadd-b677-492a-d48a-5eabb7e75c63","execution":{"iopub.status.busy":"2022-03-05T22:47:50.036941Z","iopub.execute_input":"2022-03-05T22:47:50.037218Z","iopub.status.idle":"2022-03-05T22:47:50.047022Z","shell.execute_reply.started":"2022-03-05T22:47:50.037187Z","shell.execute_reply":"2022-03-05T22:47:50.046084Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"# **Defining our model: Bidirectional LSTM** 🚀\n","metadata":{"id":"wonzjGKQnfrD"}},{"cell_type":"code","source":"## Architecture\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(100,input_shape=(64,100),return_sequences=True)))\nmodel.add(LSTM(64,return_sequences=False))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(3e-4),metrics=[\"accuracy\"])\n","metadata":{"id":"iYBUoUHJOL-u","execution":{"iopub.status.busy":"2022-03-05T22:51:50.168668Z","iopub.execute_input":"2022-03-05T22:51:50.169485Z","iopub.status.idle":"2022-03-05T22:51:50.205739Z","shell.execute_reply.started":"2022-03-05T22:51:50.169446Z","shell.execute_reply":"2022-03-05T22:51:50.205019Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#EarlyStopping after 10 times if val_loss doesnt improve  \nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nname = 'Bi-LSTM-Model'\nearly_stopping =EarlyStopping(monitor='val_loss', patience=10, verbose= True)\nbst_model_path = name + '.h5'\nmodel_checkpoint = ModelCheckpoint(bst_model_path,\n                                   save_best_only=True, mode='auto',period=1) ","metadata":{"id":"5RTnSVCKzYeS","execution":{"iopub.status.busy":"2022-03-05T22:56:07.074461Z","iopub.execute_input":"2022-03-05T22:56:07.074728Z","iopub.status.idle":"2022-03-05T22:56:07.080968Z","shell.execute_reply.started":"2022-03-05T22:56:07.074699Z","shell.execute_reply":"2022-03-05T22:56:07.080288Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#callbacks = [early_stopping, model_checkpoint]\nModel_his = model.fit(embedding_matrix_train,train_labels,epochs=50,batch_size=256,validation_data=(embedding_matrix_val, val_labels),callbacks = [early_stopping, model_checkpoint])\n","metadata":{"id":"hxemeOPxBnbl","outputId":"b964fc0c-1b1c-4e6b-dccc-d39d3964977b","execution":{"iopub.status.busy":"2022-03-05T22:56:28.216798Z","iopub.execute_input":"2022-03-05T22:56:28.217059Z","iopub.status.idle":"2022-03-05T22:57:50.804152Z","shell.execute_reply.started":"2022-03-05T22:56:28.217030Z","shell.execute_reply":"2022-03-05T22:57:50.803277Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# **Prediction** 🎊","metadata":{}},{"cell_type":"code","source":"\nbest_model = model_checkpoint.model\n# predict the value with test data\npred = best_model.predict(embedding_matrix_test)\npred_lab = np.argmax(pred, axis = 1)\n# Accuracy\nprint(\"accuracy :\",accuracy_score(pred_lab, test_labels))\n# F1 Score\nprint(\"f1 score :\",f1_score(pred_lab, test_labels, average= 'macro'))\n# Precision\nprint(\"precision :\",precision_score(pred_lab, test_labels, average= 'macro'))\n# Recall\nprint(\"Recall :\",recall_score(pred_lab, test_labels, average= 'macro'))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:57:58.045913Z","iopub.execute_input":"2022-03-05T22:57:58.049347Z","iopub.status.idle":"2022-03-05T22:58:58.301827Z","shell.execute_reply.started":"2022-03-05T22:57:58.049305Z","shell.execute_reply":"2022-03-05T22:58:58.300058Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"ev=\"accuracy\"\nplt.figure(figsize = (12,8))\nplt.plot(Model_his.history[ev], color = 'orange', alpha = 0.8)\nplt.plot(Model_his.history['val_' + ev], color  = 'lightblue', alpha = 0.8)\nplt.title('model evaluation of {}'.format(ev), fontsize = 20)\nplt.ylabel(ev)\nplt.xlabel('epoch')\nplt.legend(['accuracy', 'val_accuracy'], loc='upper left', fontsize = 18)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T23:02:11.917637Z","iopub.execute_input":"2022-03-05T23:02:11.918193Z","iopub.status.idle":"2022-03-05T23:02:12.124812Z","shell.execute_reply.started":"2022-03-05T23:02:11.918153Z","shell.execute_reply":"2022-03-05T23:02:12.124136Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"ev=\"loss\"\nax = plt.figure(figsize = (12,8))\nplt.plot(Model_his.history[ev], color = 'orange', alpha = 0.8)\nplt.plot(Model_his.history['val_' + ev], color  = 'lightblue', alpha = 0.8)\nplt.title('model evaluation of {}'.format(ev), fontsize = 20)\nplt.ylabel(ev)\nplt.xlabel('epoch')\nplt.legend(['loss', 'val_loss'], loc='upper right', fontsize = 18)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T23:04:50.288362Z","iopub.execute_input":"2022-03-05T23:04:50.288935Z","iopub.status.idle":"2022-03-05T23:04:50.481235Z","shell.execute_reply.started":"2022-03-05T23:04:50.288894Z","shell.execute_reply":"2022-03-05T23:04:50.480595Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"pred=model.predict(embedding_matrix_test)\n#print(metrics.classification_report(test_labels, pred))\npred_classes=np.argmax(pred, axis=1)\n#test_labels_=np.argmax(test_labels, axis=1)\ncm = confusion_matrix(test_labels, pred_classes)\nprint(cm)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:12:59.249436Z","iopub.execute_input":"2022-03-05T23:12:59.250110Z","iopub.status.idle":"2022-03-05T23:13:00.453878Z","shell.execute_reply.started":"2022-03-05T23:12:59.250071Z","shell.execute_reply":"2022-03-05T23:13:00.453060Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"ax = sns.heatmap(cm/np.sum(cm), annot=True, \n            fmt='.2%', cmap='Blues')\n\nax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\nax.set_xlabel('\\nPredicted News headlines sentiments')\nax.set_ylabel('Actual News headlines sentiments ');\n\n##  labels - List must be in alphabetical order\nax.xaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\nax.yaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\n\n## Display the visualization of the Confusion Matrix.\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:05:30.538131Z","iopub.execute_input":"2022-03-05T23:05:30.538406Z","iopub.status.idle":"2022-03-05T23:05:30.763345Z","shell.execute_reply.started":"2022-03-05T23:05:30.538357Z","shell.execute_reply":"2022-03-05T23:05:30.762728Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"#tf.keras.backend.clear_session()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T11:38:04.869628Z","iopub.execute_input":"2022-03-05T11:38:04.870220Z","iopub.status.idle":"2022-03-05T11:38:04.900471Z","shell.execute_reply.started":"2022-03-05T11:38:04.870181Z","shell.execute_reply":"2022-03-05T11:38:04.899768Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"**We'll use emojis for the prediction instead of numbers :**\n* (0) 😞\n\n* (1) 😐\n\n* (2) 😃","metadata":{}},{"cell_type":"code","source":"dic_emj={\"0\":\":disappointed:\",\n        \"1\":\":neutral_face:\",\n        \"2\":\":smiley:\"}\ntest_pred = pd.DataFrame(testdata[\"news\"][:30]) #Put the news into a dataframe\npd.set_option('display.max_columns', None)  \n\ntest_pred[\"pred_sentiments\"]=pred_classes[:30]\ntest_pred[\"sentiments\"]=testdata[\"sentiments\"][:30]\n\n#test_pred = pd.DataFrame() #Put the news into a dataframe\nfor i in range(30):\n    test_pred[\"sentiments\"][i]=emoji.emojize(dic_emj[str(testdata[\"sentiments\"][i])], use_aliases=True)\n    test_pred[\"pred_sentiments\"][i] =emoji.emojize(dic_emj[str(pred_classes[i])], use_aliases=True) \nHTML(test_pred.to_html())\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-05T23:17:18.956129Z","iopub.execute_input":"2022-03-05T23:17:18.956432Z","iopub.status.idle":"2022-03-05T23:17:18.977364Z","shell.execute_reply.started":"2022-03-05T23:17:18.956398Z","shell.execute_reply":"2022-03-05T23:17:18.976650Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}